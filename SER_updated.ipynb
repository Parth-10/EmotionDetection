{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\bhavana kasote\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.63.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhavana kasote\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "import os  # interface with underlying OS that python is running on\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#!pip install tqdm\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import glob\n",
    "# import keras\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import plotly.tools as tls\n",
    "import tensorflow as tf\n",
    "from playsound import playsound\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.callbacks import History, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.utils import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels source                                               path\n",
       "0  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...\n",
       "1  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...\n",
       "2  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...\n",
       "3  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...\n",
       "4  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pd.read_csv(\"D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\SER\\Data_path.csv\")#, usecols=['path'])\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12162,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this takes a couple of minutes (~10 mins) as we're iterating over 4 datasets \n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "\n",
    "# loop feature extraction over the entire dataset\n",
    "counter=0\n",
    "for index,path in enumerate(ref.path):\n",
    "    X, sample_rate = librosa.load(path\n",
    "                                  , res_type='kaiser_fast'\n",
    "                                  ,duration=2.5\n",
    "                                  ,sr=44100\n",
    "                                  ,offset=0.5\n",
    "                                 )\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    # mean as the feature. Could do min and max etc as well. \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=13),\n",
    "                    axis=0)\n",
    "    df.loc[counter] = [mfccs]\n",
    "    counter=counter+1   \n",
    "\n",
    "# Check a few records to make sure its processed successfully\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>source</th>\n",
       "      <th>path</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "      <td>-11.113933</td>\n",
       "      <td>-7.215756</td>\n",
       "      <td>-6.219190</td>\n",
       "      <td>-5.926542</td>\n",
       "      <td>-5.850419</td>\n",
       "      <td>-4.808960</td>\n",
       "      <td>-2.513003</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.088852</td>\n",
       "      <td>-5.023864</td>\n",
       "      <td>-5.254714</td>\n",
       "      <td>-5.234095</td>\n",
       "      <td>-5.310307</td>\n",
       "      <td>-5.621666</td>\n",
       "      <td>-6.072197</td>\n",
       "      <td>-6.611348</td>\n",
       "      <td>-2.509089</td>\n",
       "      <td>1.964608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "      <td>-24.449831</td>\n",
       "      <td>-22.465742</td>\n",
       "      <td>-22.928043</td>\n",
       "      <td>-23.243807</td>\n",
       "      <td>-22.926605</td>\n",
       "      <td>-23.432241</td>\n",
       "      <td>-14.830004</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.627258</td>\n",
       "      <td>-22.633406</td>\n",
       "      <td>-22.511597</td>\n",
       "      <td>-24.300154</td>\n",
       "      <td>-24.496809</td>\n",
       "      <td>-22.895985</td>\n",
       "      <td>-23.511503</td>\n",
       "      <td>-24.342152</td>\n",
       "      <td>-24.530262</td>\n",
       "      <td>-25.457796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "      <td>-25.000114</td>\n",
       "      <td>-24.520256</td>\n",
       "      <td>-24.178183</td>\n",
       "      <td>-23.847450</td>\n",
       "      <td>-15.182783</td>\n",
       "      <td>-10.732485</td>\n",
       "      <td>-8.681472</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "      <td>-1.529839</td>\n",
       "      <td>-4.333437</td>\n",
       "      <td>-12.285238</td>\n",
       "      <td>-13.083024</td>\n",
       "      <td>-12.041327</td>\n",
       "      <td>-11.819768</td>\n",
       "      <td>-9.414148</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...</td>\n",
       "      <td>-22.458635</td>\n",
       "      <td>-22.467834</td>\n",
       "      <td>-25.884357</td>\n",
       "      <td>-27.827044</td>\n",
       "      <td>-27.593534</td>\n",
       "      <td>-26.666508</td>\n",
       "      <td>-18.659023</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.291666</td>\n",
       "      <td>-25.854906</td>\n",
       "      <td>-26.821354</td>\n",
       "      <td>-25.436455</td>\n",
       "      <td>-24.179941</td>\n",
       "      <td>-23.281618</td>\n",
       "      <td>-24.167494</td>\n",
       "      <td>-25.228062</td>\n",
       "      <td>-25.902941</td>\n",
       "      <td>-25.589964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels source                                               path  \\\n",
       "0  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...   \n",
       "1  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...   \n",
       "2  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...   \n",
       "3  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...   \n",
       "4  male_angry  SAVEE  D:\\BE_PROJECT\\Speech-Emotion-Recognition-main\\...   \n",
       "\n",
       "           0          1          2          3          4          5  \\\n",
       "0 -11.113933  -7.215756  -6.219190  -5.926542  -5.850419  -4.808960   \n",
       "1 -24.449831 -22.465742 -22.928043 -23.243807 -22.926605 -23.432241   \n",
       "2 -25.000114 -24.520256 -24.178183 -23.847450 -15.182783 -10.732485   \n",
       "3  -1.529839  -4.333437 -12.285238 -13.083024 -12.041327 -11.819768   \n",
       "4 -22.458635 -22.467834 -25.884357 -27.827044 -27.593534 -26.666508   \n",
       "\n",
       "           6  ...        206        207        208        209        210  \\\n",
       "0  -2.513003  ...  -4.088852  -5.023864  -5.254714  -5.234095  -5.310307   \n",
       "1 -14.830004  ... -22.627258 -22.633406 -22.511597 -24.300154 -24.496809   \n",
       "2  -8.681472  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "3  -9.414148  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "4 -18.659023  ... -25.291666 -25.854906 -26.821354 -25.436455 -24.179941   \n",
       "\n",
       "         211        212        213        214        215  \n",
       "0  -5.621666  -6.072197  -6.611348  -2.509089   1.964608  \n",
       "1 -22.895985 -23.511503 -24.342152 -24.530262 -25.457796  \n",
       "2        NaN        NaN        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN        NaN        NaN  \n",
       "4 -23.281618 -24.167494 -25.228062 -25.902941 -25.589964  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract the mean bands to its own feature columns\n",
    "df = pd.concat([ref,pd.DataFrame(df['feature'].values.tolist())],axis=1)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)\n",
    "print(df.shape)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lts do data normalization \n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "# Check the dataset now \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from keras.utils.np_utils import *\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "# Lets few preparation steps to get it into the correct format for Keras \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))\n",
    "print(X_train.shape)\n",
    "print(lb.classes_)\n",
    "#print(y_train[0:10])#print(y_test[0:10])\n",
    "# Pickel the lb object for future use \n",
    "filename = 'labels'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  New model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(14)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00001, decay=1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train, batch_size=1, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt, metrics=['accuracy']) #fscore])\n",
    "\n",
    "# # removing whole training part for avoiding epochs list\n",
    "# lr_reduce = ReduceLROnPlateau(\n",
    "#     monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
    "# mcp_save = ModelCheckpoint('model/aug_noiseNshift_2class_2_np.h5',\n",
    "#                            save_best_only=True, monitor='val_loss', mode='min')\n",
    "# cnnhistory = model.fit(X_train, y_train, batch_size=1, epochs=10, validation_data=(\n",
    "#     X_test, y_test), callbacks=[mcp_save,lr_reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "model_name = 'Emotion_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Save model and weights at %s ' % model_path)\n",
    "\n",
    "# Save the model to disk\n",
    "model_json = model.to_json()\n",
    "with open(\"model_json.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# Keras optimiser\n",
    "opt = keras.optimizers.SGD(lr=0.00001, decay=0.0)\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(X_test, \n",
    "                         batch_size=1, \n",
    "                         verbose=1)\n",
    "\n",
    "preds=preds.argmax(axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "preds = preds.astype(int).flatten()\n",
    "preds = (lb.inverse_transform((preds)))\n",
    "preds = pd.DataFrame({'predictedvalues': preds})\n",
    "\n",
    "# Actual labels\n",
    "actual=y_test.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n",
    "actual = (lb.inverse_transform((actual)))\n",
    "actual = pd.DataFrame({'actualvalues': actual})\n",
    "\n",
    "# Lets combined both of them into a single dataframe\n",
    "finaldf = actual.join(preds)\n",
    "finaldf[170:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the predictions to disk\n",
    "finaldf.to_csv('Predictions.csv', index=False)\n",
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the confusion matrix heat map plot\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "        \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Gender recode function\n",
    "def gender(row):\n",
    "    if row == 'female_disgust' or 'female_fear' or 'female_happy' or 'female_sad' or 'female_surprise' or 'female_neutral':\n",
    "        return 'female'\n",
    "    elif row == 'male_angry' or 'male_fear' or 'male_happy' or 'male_sad' or 'male_surprise' or 'male_neutral' or 'male_disgust':\n",
    "        return 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions file \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "finaldf = pd.read_csv(\"Predictions.csv\")\n",
    "classes = finaldf.actualvalues.unique()\n",
    "classes.sort()    \n",
    "\n",
    "# Confusion matrix \n",
    "c = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\n",
    "print(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\n",
    "print_confusion_matrix(c, class_names = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classes = finaldf.actualvalues.unique()\n",
    "classes.sort()    \n",
    "print(classification_report(finaldf.actualvalues, finaldf.predictedvalues, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modidf = finaldf\n",
    "modidf['actualvalues'] = finaldf.actualvalues.replace({'female_angry':'female'\n",
    "                                       , 'female_disgust':'female'\n",
    "                                       , 'female_fear':'female'\n",
    "                                       , 'female_happy':'female'\n",
    "                                       , 'female_sad':'female'\n",
    "                                       , 'female_surprise':'female'\n",
    "                                       , 'female_neutral':'female'\n",
    "                                       , 'male_angry':'male'\n",
    "                                       , 'male_fear':'male'\n",
    "                                       , 'male_happy':'male'\n",
    "                                       , 'male_sad':'male'\n",
    "                                       , 'male_surprise':'male'\n",
    "                                       , 'male_neutral':'male'\n",
    "                                       , 'male_disgust':'male'\n",
    "                                      })\n",
    "\n",
    "modidf['predictedvalues'] = finaldf.predictedvalues.replace({'female_angry':'female'\n",
    "                                       , 'female_disgust':'female'\n",
    "                                       , 'female_fear':'female'\n",
    "                                       , 'female_happy':'female'\n",
    "                                       , 'female_sad':'female'\n",
    "                                       , 'female_surprise':'female'\n",
    "                                       , 'female_neutral':'female'\n",
    "                                       , 'male_angry':'male'\n",
    "                                       , 'male_fear':'male'\n",
    "                                       , 'male_happy':'male'\n",
    "                                       , 'male_sad':'male'\n",
    "                                       , 'male_surprise':'male'\n",
    "                                       , 'male_neutral':'male'\n",
    "                                       , 'male_disgust':'male'\n",
    "                                      })\n",
    "\n",
    "classes = modidf.actualvalues.unique()  \n",
    "classes.sort() \n",
    "\n",
    "# Confusion matrix \n",
    "c = confusion_matrix(modidf.actualvalues, modidf.predictedvalues)\n",
    "print(accuracy_score(modidf.actualvalues, modidf.predictedvalues))\n",
    "print_confusion_matrix(c, class_names = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = modidf.actualvalues.unique()\n",
    "classes.sort()    \n",
    "print(classification_report(modidf.actualvalues, modidf.predictedvalues, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modidf = pd.read_csv(\"Predictions.csv\")\n",
    "modidf['actualvalues'] = modidf.actualvalues.replace({'female_angry':'angry'\n",
    "                                       , 'female_disgust':'disgust'\n",
    "                                       , 'female_fear':'fear'\n",
    "                                       , 'female_happy':'happy'\n",
    "                                       , 'female_sad':'sad'\n",
    "                                       , 'female_surprise':'surprise'\n",
    "                                       , 'female_neutral':'neutral'\n",
    "                                       , 'male_angry':'angry'\n",
    "                                       , 'male_fear':'fear'\n",
    "                                       , 'male_happy':'happy'\n",
    "                                       , 'male_sad':'sad'\n",
    "                                       , 'male_surprise':'surprise'\n",
    "                                       , 'male_neutral':'neutral'\n",
    "                                       , 'male_disgust':'disgust'\n",
    "                                      })\n",
    "\n",
    "modidf['predictedvalues'] = modidf.predictedvalues.replace({'female_angry':'angry'\n",
    "                                       , 'female_disgust':'disgust'\n",
    "                                       , 'female_fear':'fear'\n",
    "                                       , 'female_happy':'happy'\n",
    "                                       , 'female_sad':'sad'\n",
    "                                       , 'female_surprise':'surprise'\n",
    "                                       , 'female_neutral':'neutral'\n",
    "                                       , 'male_angry':'angry'\n",
    "                                       , 'male_fear':'fear'\n",
    "                                       , 'male_happy':'happy'\n",
    "                                       , 'male_sad':'sad'\n",
    "                                       , 'male_surprise':'surprise'\n",
    "                                       , 'male_neutral':'neutral'\n",
    "                                       , 'male_disgust':'disgust'\n",
    "                                      })\n",
    "\n",
    "classes = modidf.actualvalues.unique() \n",
    "classes.sort() \n",
    "\n",
    "# Confusion matrix \n",
    "c = confusion_matrix(modidf.actualvalues, modidf.predictedvalues)\n",
    "print(accuracy_score(modidf.actualvalues, modidf.predictedvalues))\n",
    "print_confusion_matrix(c, class_names = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report \n",
    "classes = modidf.actualvalues.unique()\n",
    "classes.sort()    \n",
    "print(classification_report(modidf.actualvalues, modidf.predictedvalues, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('C:\\\\Users\\\\Kunal Bhapkar\\\\Downloads\\\\praddyumn_2.wav')\n",
    "ipd.Audio('C:\\\\Users\\\\Kunal Bhapkar\\\\Downloads\\\\praddyumn_2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading json and model architecture \n",
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# the optimiser\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading json and model architecture \n",
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# the optimiser\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load('C:\\\\Users\\\\Kunal Bhapkar\\\\Downloads\\\\praddyumn_2.wav'\n",
    "                              ,res_type='kaiser_fast'\n",
    "                              ,duration=2.5\n",
    "                              ,sr=44100\n",
    "                              ,offset=0.5\n",
    "                             )\n",
    "\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "newdf = pd.DataFrame(data=mfccs).T\n",
    "\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply predictions\n",
    "newdf= np.expand_dims(newdf, axis=2)\n",
    "newpred = loaded_model.predict(newdf, \n",
    "                         batch_size=16, \n",
    "                         verbose=1)\n",
    "\n",
    "newpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '/kaggle/input/labels/labels'\n",
    "import pickle\n",
    "filename = 'labels'\n",
    "infile = open(filename,'rb')\n",
    "lb = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "\n",
    "# Get the final predicted label\n",
    "final = newpred.argmax(axis=1)\n",
    "final = final.astype(int).flatten()\n",
    "final = (lb.inverse_transform((final)))\n",
    "print(final) #emo(final) #gender(final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
